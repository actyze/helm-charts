# Production Environment Configuration
# This file contains settings for Azure AKS deployment

# Environment identifier
environment: production

# Global configuration
global:
  namespace: dashboard
  imagePullPolicy: Always  # Always pull latest from Docker Hub
  storageClass: "managed-csi"
  
  # Docker Hub credentials for private repository
  imageRegistry: "docker.io/yourusername"  # Replace with your Docker Hub username
  imagePullSecrets:
    - name: dockerhub-secret

# ============================================================================
# PRODUCTION SECRET MANAGEMENT
# ============================================================================
secrets:
  create: false  # Secrets managed externally in production
  
  # External LLM configuration (managed via script or CI/CD)
  externalLLM:
    apiKey: ""  # Loaded from dashboard-external-llm secret
    
  # Trino credentials (managed via script or CI/CD)
  trino:
    username: ""  # Loaded from dashboard-trino-credentials secret
    password: ""  # Loaded from dashboard-trino-credentials secret
    
  # PostgreSQL database credentials
  postgres:
    username: ""
    password: ""

# ============================================================================
# MODEL STRATEGY - Choose ONE approach for SQL generation
# ============================================================================
modelStrategy:
  # Option 1: External LLM APIs (Recommended for production)
  externalLLM:
    enabled: true              # ← Toggle: Use external LLM (production default)
    provider: "perplexity"     # Options: openai, perplexity, anthropic, groq, together
    model: "sonar-reasoning-pro"
    baseUrl: "https://api.perplexity.ai"
    apiKey: "${EXTERNAL_LLM_API_KEY}"  # MUST be from Kubernetes secret in production
    maxTokens: 1000
    temperature: 0.1
    timeout: 30s
    fallbackToLocal: false     # No fallback in production
    
  # Option 2: Local Phi-4 LoRA Model (Can enable for hybrid or cost optimization)
  phiSqlLora:
    enabled: false             # ← Toggle: Use local Phi-4-mini LoRA model
    replicas: 2                # High availability in production
    deploymentMode: "t4"       # Options: "t4", "api_key" (no MPS in production)
    
    # T4 GPU Configuration (Production)
    t4:
      enabled: true
      resources:
        requests:
          memory: "4Gi"        # T4 FP16 optimized
          cpu: "2000m"
          nvidia.com/gpu: 1
        limits:
          memory: "8Gi"
          cpu: "4000m"
          nvidia.com/gpu: 1
      nodeSelector:
        accelerator: nvidia-tesla-t4
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
        
    # API Key Configuration (Production Fallback)
    apiKey:
      enabled: false
      provider: "perplexity"
      endpoint: "https://api.perplexity.ai"
      model: "sonar-reasoning-pro"
      apiKey: "${EXTERNAL_LLM_API_KEY}"  # From Kubernetes secret
      resources:
        requests:
          memory: "256Mi"
          cpu: "100m"
        limits:
          memory: "512Mi"
          cpu: "200m"

# Service Account
serviceAccount:
  create: true
  automount: true
  annotations:
    azure.workload.identity/client-id: ""  # Add your Azure Managed Identity
  name: ""

# ============================================================================
# SERVICES - Enable/disable individual components
# ============================================================================
services:
  # Core Services (required)
  nexus:
    enabled: true        # ← Nexus orchestration service (REQUIRED) - replaces backend
  
  # Optional Services
  frontend:
    enabled: true        # ← React UI
  schemaService:
    enabled: true        # ← FAISS-based schema recommendations
  trino:
    enabled: true        # ← Query execution engine
  
  # PostgreSQL Database (operational database)
  postgres:
    enabled: true        # ← PostgreSQL operational database

# Nexus FastAPI service (replaces Spring Boot backend)
nexus:
  replicaCount: 3        # High availability
  image:
    repository: yourusername/dashboard-nexus  # Replace yourusername with your Docker Hub username
    tag: latest  # Always pull latest
    pullPolicy: Always
  service:
    type: ClusterIP
    port: 8002  # Nexus runs on port 8002
  resources:
    requests:
      memory: "512Mi"
      cpu: "250m"
    limits:
      memory: "1Gi"
      cpu: "500m"
  env:
    # Database Configuration
    postgres:
      host: "dashboard-postgres"
      port: 5432
      database: "dashboard"
      # user and password loaded from Kubernetes secrets
    # Cache Configuration (In-Memory - Enterprise Grade)
    cache:
      enabled: true
      type: "memory"
      queryMaxSize: 1000
      llmMaxSize: 200
      llmTtl: 7200
    # External Services
    schemaService:
      url: "http://dashboard-schema-service:8001"
    # LLM Configuration
    externalLlm:
      enabled: true
      provider: "perplexity"
      model: "sonar-reasoning-pro"
      # apiKey loaded from secret

# Frontend React service
frontend:
  replicaCount: 3
  image:
    repository: yourusername/dashboard-frontend  # Replace yourusername with your Docker Hub username
    tag: latest  # Always pull latest
    pullPolicy: Always
  service:
    type: ClusterIP
    port: 3000
  resources:
    requests:
      memory: "128Mi"
      cpu: "100m"
    limits:
      memory: "256Mi"
      cpu: "200m"

# Schema Service (FAISS)
schemaService:
  replicaCount: 2
  image:
    repository: yourusername/dashboard-schema-service  # Replace yourusername with your Docker Hub username
    tag: latest  # Always pull latest
    pullPolicy: Always
  resources:
    requests:
      memory: "1Gi"
      cpu: "500m"
    limits:
      memory: "2Gi"
      cpu: "1000m"
  env:
    includeTpch: false  # Exclude TPC-H sample data in production

# Trino database service
trino:
  replicaCount: 3
  image:
    repository: trinodb/trino
    tag: "477"
  service:
    type: ClusterIP
    port: 8080
  resources:
    requests:
      memory: "2Gi"
      cpu: "1000m"
    limits:
      memory: "4Gi"
      cpu: "2000m"

# Ingress configuration
ingress:
  enabled: true
  className: "nginx"
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
  hosts:
    - host: dashboard.yourdomain.com
      paths:
        - path: /
          pathType: Prefix
          service: frontend
        - path: /api
          pathType: Prefix
          service: nexus
  tls:
    - secretName: dashboard-tls
      hosts:
        - dashboard.yourdomain.com

# Autoscaling
autoscaling:
  nexus:
    enabled: true
    minReplicas: 3
    maxReplicas: 10
    targetCPUUtilizationPercentage: 70
  frontend:
    enabled: true
    minReplicas: 3
    maxReplicas: 8
    targetCPUUtilizationPercentage: 70
  schemaService:
    enabled: true
    minReplicas: 2
    maxReplicas: 6
    targetCPUUtilizationPercentage: 75
  phiSqlLora:
    enabled: false
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80

# Pod Disruption Budget
podDisruptionBudget:
  enabled: true
  minAvailable: 2

# Network Policy
networkPolicy:
  enabled: true

# Service Monitor (Prometheus)
serviceMonitor:
  enabled: true

# Logging configuration
logging:
  level:
    root: INFO
    dashboard: INFO

# Monitoring configuration
monitoring:
  metrics:
    enabled: true
    scrapeInterval: 30s

# Database Migrations Configuration
migrations:
  # Run DML (Data Manipulation Language) scripts?
  # DDL (schema changes) always runs automatically
  # DML (demo data inserts) only runs when enabled
  runDML: false  # PRODUCTION: Never run demo data in production

# ============================================================================
# NOTE: API keys should be injected via Kubernetes secrets in production
# Never commit actual API keys to version control
# ============================================================================
