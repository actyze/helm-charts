# Development Environment Configuration
# This file contains settings for local Kind cluster deployment

# Environment identifier
environment: dev

# Global configuration
global:
  namespace: dashboard
  imagePullPolicy: IfNotPresent  # Allow pulling public images
  storageClass: "standard"
  
  # Local development - no registry needed for Kind
  imageRegistry: ""
  imagePullSecrets: []

# ============================================================================
# DEVELOPMENT SECRET MANAGEMENT
# ============================================================================
# ⚠️  SECRETS ARE EXTERNALIZED - NOT IN GIT
# Copy values-dev-secrets.yaml.example to values-dev-secrets.yaml
# Fill in your actual secrets in values-dev-secrets.yaml (not committed to Git)
secrets:
  create: true  # Create secrets from values for development convenience
  
  # External LLM configuration - LOADED FROM values-dev-secrets.yaml
  externalLLM:
    apiKey: ""  # ⚠️  MUST be provided in values-dev-secrets.yaml
    
  # Trino credentials - LOADED FROM values-dev-secrets.yaml  
  trino:
    username: ""  # ⚠️  MUST be provided in values-dev-secrets.yaml
    password: ""  # ⚠️  MUST be provided in values-dev-secrets.yaml
    
  # PostgreSQL database credentials - LOADED FROM values-dev-secrets.yaml
  postgres:
    username: ""  # ⚠️  LOADED from values-dev-secrets.yaml
    password: ""  # ⚠️  LOADED from values-dev-secrets.yaml

# ============================================================================
# MODEL STRATEGY - Choose ONE approach for SQL generation
# ============================================================================
modelStrategy:
  # Option 1: External LLM APIs (Recommended for dev/testing)
  externalLLM:
    enabled: true              # ← Toggle: Use external LLM (OpenAI, Perplexity, Claude, etc.)
    provider: "perplexity"     # Options: openai, perplexity, anthropic, groq, together
    model: "sonar-reasoning-pro"
    baseUrl: "https://api.perplexity.ai/chat/completions"  # Complete endpoint URL
    # Examples for other providers:
    # OpenAI: "https://api.openai.com/v1/chat/completions"
    # Groq: "https://api.groq.com/openai/v1/chat/completions"  
    # Together: "https://api.together.xyz/v1/chat/completions"
    # apiKey loaded from secret: dashboard-external-llm
    maxTokens: 1000
    temperature: 0.1
    timeout: 30
    fallbackToLocal: false     # Don't fallback to local model if external fails
    
  # Option 2: Local Phi-4 LoRA Model (configuration in phiSqlLora section below)
  phiSqlLora:
    enabled: false             # ← Toggle: Use local Phi-4-mini LoRA model

# Service Account
serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Automatically mount a ServiceAccount's API credentials?
  automount: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

# ============================================================================
# SERVICES - Enable/disable individual components
# ============================================================================
services:
  # Core Services (required)
  nexus:
    enabled: true        # Nexus orchestration service (REQUIRED) - replaces backend
  frontend:
    enabled: true        # React frontend (REQUIRED)
  schemaService:
    enabled: true        # FAISS schema recommendations (REQUIRED)
  
  # Database Services (required)
  postgres:
    enabled: true        # PostgreSQL database (REQUIRED)
  trino:
    enabled: true        # Trino query engine (REQUIRED)
  
  # Disabled Services
  backend:
    enabled: false       # Old Java backend (DISABLED) - replaced by nexus
  phiSqlLora:
    enabled: false       # Local LLM service (DISABLED) - using external LLM

# Nexus FastAPI service (replaces Spring Boot backend)
nexus:
  replicaCount: 1
  image:
    repository: dashboard-nexus  # Nexus service image
    tag: latest
    pullPolicy: Never  # Use local images for Kind
  service:
    type: ClusterIP
    port: 8002  # FastAPI Nexus service runs on port 8002
  resources:
    requests:
      memory: "512Mi"
      cpu: "250m"
    limits:
      memory: "1Gi"
      cpu: "500m"
  env:
    # Database Configuration
    postgres:
      host: "dashboard-postgres"
      port: 5432
      database: "dashboard"
      # user and password loaded from values-dev-secrets.yaml
    # Cache Configuration (In-Memory - No Redis)
    cache:
      enabled: true
      type: "memory"
      queryMaxSize: 1000
      llmMaxSize: 200
      llmTtl: 7200
    # External Services
    schemaService:
      url: "http://dashboard-schema-service:8001"
    phiSqlLora:
      url: "http://dashboard-phi-sql-lora:8000"  # Available but disabled
    trino:
      # All Trino connection details loaded from values-dev-secrets.yaml
      # host, port, catalog, schema, user, password
    # ML Service Configuration
    mlService:
      modelType: "external-llm"
    # SQL Execution Configuration
    sqlExecution:
      defaultMaxResults: 100
      defaultTimeoutSeconds: 30
    # LLM Configuration
    externalLlm:
      enabled: true
      provider: "perplexity"
      model: "sonar-reasoning-pro"
      # apiKey loaded from secret

# Frontend React service
frontend:
  replicaCount: 1
  image:
    repository: dashboard-frontend
    tag: latest
    pullPolicy: Never  # Use local images for Kind
  service:
    type: ClusterIP
    port: 3000
  resources:
    requests:
      memory: "128Mi"
      cpu: "100m"
    limits:
      memory: "256Mi"
      cpu: "200m"

# Ingress configuration
ingress:
  enabled: true
  className: "nginx"
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
  hosts:
    - host: dashboard.local
      paths:
        - path: /
          pathType: Prefix
          service: frontend
        - path: /api
          pathType: Prefix
          service: nexus
  tls: []

# Service Monitor for Prometheus (optional)
serviceMonitor:
  enabled: false
  namespace: monitoring
  interval: 30s

# Horizontal Pod Autoscaler (disabled for dev)
autoscaling:
  nexus:
    enabled: false
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 80
  frontend:
    enabled: false
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 80
  schemaService:
    enabled: false  # Schema service typically doesn't need autoscaling in dev

# Network Policies
networkPolicy:
  enabled: false

# Pod Disruption Budgets
podDisruptionBudget:
  enabled: true
  minAvailable: 1

# External Trino configuration removed - each service has its own explicit trino config

# Trino database service (when services.trino.enabled = true)
trino:
  replicaCount: 1
  image:
    repository: trinodb/trino
    tag: "477"
  service:
    type: ClusterIP
    port: 8080
  resources:
    requests:
      memory: "4Gi"        # ↑ Maximum memory for aggressive query caching
      cpu: "2500m"         # ↑ High CPU for maximum parallel processing
    limits:
      memory: "8Gi"        # ↑ Large headroom for complex analytics
      cpu: "4000m"         # ↑ Maximum CPU for concurrent query execution
  environment: "production"
  nodeId: "ffffffff-ffff-ffff-ffff-ffffffffffff"
  jvm:
    maxHeapSize: "6G"      # ↑ 3x JVM heap for optimal performance
  config:
    enabled: true
  catalogs:
    postgres:
      connector.name: "postgresql"
      connection-url: "jdbc:postgresql://dashboard-postgres:5432/dashboard"
      connection-user: "nexus_service"
      connection-password: "${ENV:POSTGRES_PASSWORD}"
    memory:
      connector.name: "memory"
    tpch:
      connector.name: "tpch"
      tpch.splits-per-node: "4"
  livenessProbe:
    initialDelaySeconds: 60
    periodSeconds: 30
    timeoutSeconds: 10
    failureThreshold: 3
  readinessProbe:
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3

# PostgreSQL operational database configuration
postgres:
  image:
    repository: postgres
    tag: "15-alpine"
  database: "dashboard"
  # user and password loaded from values-dev-secrets.yaml
  
  # Persistence configuration
  persistence:
    enabled: true
    size: 5Gi
    storageClass: "standard"
    accessModes:
      - ReadWriteOnce
      
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "512Mi"
      cpu: "250m"

# Database Migrations Configuration
migrations:
  # Run DML (Data Manipulation Language) scripts?
  # DDL (schema changes) always runs automatically
  # DML (demo data inserts) only runs when enabled
  runDML: true  # Set to false for production (no demo data)

# FAISS Schema Service
schemaService:
  replicaCount: 1
  image:
    repository: dashboard-schema-service
    tag: latest
    pullPolicy: Never  # Use local images for Kind
  resources:
    requests:
      memory: "2Gi"        # ↑ Sufficient for ~1GB actual usage + overhead
      cpu: "4000m"         # ↑ 4 cores for faster multilingual MPNet embedding generation
    limits:
      memory: "4Gi"        # ↑ Reasonable limit with safety margin
      cpu: "6000m"         # ↑ 6 cores for maximum embedding performance
  env:
    trino:
      # All Trino connection details loaded from values-dev-secrets.yaml
      # host, port, catalog, schema, user, password
    refreshHours: 3
    includeTpch: true  # Include TPC-H for local development testing
  probes:
    liveness:
      initialDelaySeconds: 900    # 15 minutes buffer for embedding generation
      periodSeconds: 60
      timeoutSeconds: 30
      failureThreshold: 3
    readiness:
      initialDelaySeconds: 900    # 15 minutes buffer for embedding generation
      periodSeconds: 30
      timeoutSeconds: 5
      failureThreshold: 10
  service:
    type: ClusterIP
    port: 8001
  storage:
    enabled: true
    size: 2Gi
    storageClass: "standard"


# Phi SQL LoRA Service (T4 GPU Only) - Optional
phiSqlLora:
  enabled: false  # Set to true to deploy local T4 GPU model
  replicaCount: 1
  
  # ============================================================================
  # T4 GPU CONFIGURATION - No CPU fallback
  # ============================================================================
  resources:
    requests:
      memory: "4Gi"      # T4 uses FP16, optimized memory usage
      cpu: "2"
      nvidia.com/gpu: 1
    limits:
      memory: "8Gi"
      cpu: "4"
      nvidia.com/gpu: 1
      
  nodeSelector:
    accelerator: nvidia-tesla-t4
    
  tolerations:
  - key: nvidia.com/gpu
    operator: Exists
    effect: NoSchedule
      
  
  image:
    repository: phi-sql-lora-unified
    tag: latest
    pullPolicy: Always
    
  service:
    type: ClusterIP
    port: 8000
    targetPort: 8000
    name: http
    
  env:
    PYTHONUNBUFFERED: "1"
    TRANSFORMERS_CACHE: "/app/model_cache"
    HF_HOME: "/app/model_cache"
    TOKENIZERS_PARALLELISM: "false"
    MODEL_NAME: "microsoft/Phi-4-mini-instruct"
    LORA_ADAPTER_PATH: "adapters/phi4-trino477-lora"
    PORT: "8000"
    
  persistence:
    enabled: true
    storageClass: "standard"
    accessMode: ReadWriteOnce
    size: 20Gi              # Reduced size, more efficient
    mountPath: /app/model_cache
    
  healthCheck:
    enabled: true
    path: /health
    port: 8000
    initialDelaySeconds: 120  # Faster startup with GPU
    periodSeconds: 30
    timeoutSeconds: 10
    failureThreshold: 3
    successThreshold: 1
    
  readinessCheck:
    enabled: true
    path: /health
    port: 8000
    initialDelaySeconds: 60   # Faster readiness with GPU
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3
    successThreshold: 1
    
  model:
    name: "phi-4-mini-trino-lora-unified"
    maxTokens: 500           # Optimized for faster inference
    temperature: 0.1
    
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
      
  securityContext:
    runAsNonRoot: false
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: false
    capabilities:
      drop:
      - ALL
      add:
      - NET_BIND_SERVICE

# Logging configuration
logging:
  level:
    dashboard: DEBUG
    root: INFO
    com.dashboard.service: DEBUG
    com.dashboard.service.LlmCommunicationService: DEBUG
    com.dashboard.service.OrchestrationService: DEBUG
    com.dashboard.service.SchemaRecommendationService: DEBUG
  files:
    application:
      path: "/app/logs/dashboard-backend.log"

# Monitoring configuration
monitoring:
  metrics:
    enabled: true

# ============================================================================
# NOTE: Model strategy is configured at the top in the modelStrategy section
# ============================================================================
